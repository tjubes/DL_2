{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b654417",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base filepath: c:\\Users\\marcd\\Desktop\\Master\\Courses\\Deep_Learning\\Project_2\\Final Project data\\Final Project data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from Utils.utilities import *\n",
    "import h5py\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Use os.path.join() to create the correct file path\n",
    "filepath = get_filepath()\n",
    "print(f\"Base filepath: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3454e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: {'task_story', 'task_working', 'rest', 'task_motor'}\n",
      "\n",
      "Loaded 32 training files and 8 test files\n",
      "Training labels: ['rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'task_motor', 'task_motor', 'task_motor', 'task_motor', 'task_motor', 'task_motor', 'task_motor', 'task_motor', 'task_story', 'task_story', 'task_story', 'task_story', 'task_story', 'task_story', 'task_story', 'task_story', 'task_working', 'task_working', 'task_working', 'task_working', 'task_working', 'task_working', 'task_working', 'task_working']\n",
      "Test labels: ['rest', 'rest', 'task_motor', 'task_motor', 'task_story', 'task_story', 'task_working', 'task_working']\n",
      "Shape of first training sample after downsampling: (248, 2227)\n"
     ]
    }
   ],
   "source": [
    "#THIS GOES TO UTLITIES.PY\n",
    "\n",
    "def load_and_normalize_files(directory_path, max_files=None, downsample_factor=None):\n",
    "    \"\"\"\n",
    "    Load and normalize all h5 files in the specified directory\n",
    "    \n",
    "    Parameters:\n",
    "    directory_path (str): Path to the directory containing h5 files\n",
    "    max_files (int, optional): Maximum number of files to load\n",
    "    downsample_factor (int, optional): Factor by which to downsample the data\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (data, labels) where data is a list of normalized matrices and labels are the corresponding task types\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get all h5 files in the directory\n",
    "    h5_files = [f for f in os.listdir(directory_path) if f.endswith('.h5')]\n",
    "    \n",
    "    # Limit the number of files if specified\n",
    "    if max_files is not None:\n",
    "        h5_files = h5_files[:max_files]\n",
    "    \n",
    "    for file in h5_files:\n",
    "       # Extract the task type from the filename\n",
    "        if file.startswith(\"task_\"):\n",
    "            parts = file.split('_')\n",
    "            task_type = '_'.join(parts[:2])  # e.g., task_motor or task_working\n",
    "        else:\n",
    "            task_type = file.split('_')[0]  # e.g., rest\n",
    "\n",
    "        # Load the data\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        matrix = read_h5py_file(file_path)\n",
    "        \n",
    "        # Downsample if specified\n",
    "        if downsample_factor is not None:\n",
    "            matrix = matrix[:, ::downsample_factor]\n",
    "        \n",
    "        # Normalize the data using scipy's zscore                                # I would try both normalizing tecniques: for channel/sample (used now) and for channel/Global\n",
    "        normalized_matrix = zscore(matrix, axis=1, nan_policy='propagate')\n",
    "        normalized_matrix = np.nan_to_num(normalized_matrix, nan=0.0)\n",
    "        \n",
    "        # Add to lists\n",
    "        data_list.append(normalized_matrix)\n",
    "        labels.append(task_type)\n",
    "    \n",
    "    return data_list, labels\n",
    "\n",
    "# Example usage for Intra-subject classification\n",
    "intra_train_path = os.path.join(filepath, \"Intra\", \"train\")\n",
    "intra_test_path = os.path.join(filepath, \"Intra\", \"test\")\n",
    "\n",
    "# Load a small subset of files to test the function\n",
    "# Downsample factor is set to 16 to speed up the process, CHANGE LATER!\n",
    "train_data, train_labels = load_and_normalize_files(intra_train_path, downsample_factor=16)\n",
    "test_data, test_labels = load_and_normalize_files(intra_test_path, downsample_factor=16)\n",
    "unique_labels = set(train_labels + test_labels)\n",
    "print(f\"Unique labels: {unique_labels}\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\nLoaded {len(train_data)} training files and {len(test_data)} test files\")\n",
    "print(f\"Training labels: {train_labels}\")\n",
    "print(f\"Test labels: {test_labels}\")\n",
    "print(f\"Shape of first training sample after downsampling: {train_data[0].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3abb8657",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Standard class mapping for MEG tasks\u001b[39;00m\n\u001b[32m     11\u001b[39m LABEL_MAP = {\n\u001b[32m     12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrest\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtask_motor\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtask_story\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtask_working\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m\n\u001b[32m     16\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mMEGDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[32m     19\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Custom Dataset for MEG data\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_list, labels):\n",
      "\u001b[31mNameError\u001b[39m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "# Standard class mapping for MEG tasks\n",
    "\n",
    "LABEL_MAP = {\n",
    "    'rest': 0,\n",
    "    'task_motor': 1, \n",
    "    'task_story': 2,\n",
    "    'task_working': 3\n",
    "}\n",
    "\n",
    "class MEGDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for MEG data\"\"\"\n",
    "    def __init__(self, data_list, labels):\n",
    "        self.data_list = data_list\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the data matrix (248, time_steps)\n",
    "        data = self.data_list[idx]\n",
    "        \n",
    "        # Add channel dimension: (248, time_steps) -> (1, 248, time_steps)\n",
    "        data = torch.FloatTensor(data).unsqueeze(0)\n",
    "        \n",
    "        # Convert string label to integer\n",
    "        label = LABEL_MAP[self.labels[idx]]\n",
    "        label = torch.LongTensor([label]).squeeze()\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "class MEGNet(nn.Module):\n",
    "    \"\"\"Smaller 2D CNN for MEG data classification\"\"\"\n",
    "    def __init__(self, num_classes=4, input_channels=248, input_time_steps=2227):\n",
    "        super(MEGNet, self).__init__()\n",
    "        \n",
    "        # Smaller conv blocks\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(8, 16), padding=(4, 8))\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(4, 8))  # More aggressive pooling\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(4, 8), padding=(2, 4))\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(4, 8))  # More aggressive pooling\n",
    "        \n",
    "        # Calculate the size after convolutions\n",
    "        self.flatten_size = self._calculate_flatten_size(input_channels, input_time_steps)\n",
    "        \n",
    "        # Smaller fully connected layers\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def _calculate_flatten_size(self, channels, time_steps):\n",
    "        \"\"\"Calculate the size after all conv+pool operations\"\"\"\n",
    "        # Simulate forward pass to get dimensions\n",
    "        x = torch.zeros(1, 1, channels, time_steps)\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        return x.numel()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Conv blocks with ReLU and pooling\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Flatten for fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Fully connected layers with dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class TinyMEGNet(nn.Module):\n",
    "    \"\"\"Very small CNN for limited MEG data\"\"\"\n",
    "    def __init__(self, num_classes=4, input_channels=248, input_time_steps=2227):\n",
    "        super(TinyMEGNet, self).__init__()\n",
    "        \n",
    "        # Aggressive downsampling with minimal parameters\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=(32, 64), stride=(8, 16))\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=(4, 8), stride=(2, 4))\n",
    "        \n",
    "        # Global average pooling instead of large FC layers\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Minimal fully connected\n",
    "        self.fc = nn.Linear(8, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        print(f\"TinyMEGNet created with {sum(p.numel() for p in self.parameters()):,} parameters\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8b2d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d58b5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "net = TinyMEGNet(num_classes=len(LABEL_MAP))\n",
    "# # net = MEGNet(num_classes=len(LABEL_MAP), \n",
    "#              input_channels=248, \n",
    "#              input_time_steps=train_data[0].shape[1])  # Use actual time steps after downsampling\n",
    "print(f\"Model created. Total parameters: {sum(p.numel() for p in net.parameters()):,}\")\n",
    "print(f\"Model input shape expected: (batch, 1, 248, {train_data[0].shape[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f064f5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_dataloaders(train_data, train_labels, test_data, test_labels, batch_size=4):\n",
    "    \"\"\"Create PyTorch DataLoaders from your loaded data\"\"\"\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = MEGDataset(train_data, train_labels)\n",
    "    test_dataset = MEGDataset(test_data, test_labels)\n",
    "    \n",
    "    # Create dataloaders with num_workers=0 to avoid multiprocessing issues\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d3fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "print(f\"Creating DataLoaders...\")\n",
    "trainloader, testloader = create_dataloaders(train_data, train_labels, test_data, test_labels, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a loss function and optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Alternative: You might also consider Adam optimizer (optim.Adam()) which adapts learning rates \n",
    "# automatically and often works well for neural networks without needing to tune momentum manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device='cpu'):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ee240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training the network\n",
    "# for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(trainloader, 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "#             running_loss = 0.0\n",
    "\n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './cifar_net.pth'\n",
    "# torch.save(net.state_dict(), PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f21377",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion, device='cpu'):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = len([1 for i, j in zip(all_predictions, all_labels) if i == j]) / len(all_labels)\n",
    "    \n",
    "    return avg_loss, accuracy, all_predictions, all_labels\n",
    "\n",
    "def cross_validation_experiment(all_data, all_labels, label_map, n_splits=4, epochs=50, batch_size=4):\n",
    "    \"\"\"Complete cross-validation experiment\"\"\"\n",
    "    \n",
    "    # Convert labels to indices\n",
    "    label_indices = [label_map[label] for label in all_labels]\n",
    "    \n",
    "    # Initialize cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Store results\n",
    "    fold_results = []\n",
    "    all_histories = []\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  CROSS-VALIDATION EXPERIMENT ({n_splits} folds)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total samples: {len(all_data)}\")\n",
    "    print(f\"Samples per fold - Train: ~{len(all_data) * (n_splits-1) // n_splits}, Val: ~{len(all_data) // n_splits}\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(all_data, label_indices)):\n",
    "        print(f\"\\n--- FOLD {fold + 1}/{n_splits} ---\")\n",
    "        \n",
    "        # Create datasets for this fold\n",
    "        full_dataset = MEGDataset(all_data, all_labels)\n",
    "        train_dataset = Subset(full_dataset, train_idx)\n",
    "        val_dataset = Subset(full_dataset, val_idx)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # Initialize model, loss, optimizer for this fold\n",
    "        model = TinyMEGNet(num_classes=len(label_map), \n",
    "                          input_channels=248, \n",
    "                          input_time_steps=all_data[0].shape[1])\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-3)\n",
    "        \n",
    "        # Training history for this fold\n",
    "        train_losses, train_accs = [], []\n",
    "        val_losses, val_accs = [], []\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        patience = 15\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            # Train\n",
    "            train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion)\n",
    "            \n",
    "            # Store history\n",
    "            train_losses.append(train_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(val_acc)\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "                print(f\"Epoch {epoch:2d}: Train Acc={train_acc:.3f}, Val Acc={val_acc:.3f}, Val Loss={val_loss:.3f}\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        \n",
    "        # Final evaluation on validation set\n",
    "        final_val_loss, final_val_acc, val_preds, val_true = evaluate_model(model, val_loader, criterion)\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold + 1,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'final_val_acc': final_val_acc,\n",
    "            'val_predictions': val_preds,\n",
    "            'val_true': val_true,\n",
    "            'train_idx': train_idx,\n",
    "            'val_idx': val_idx\n",
    "        })\n",
    "        \n",
    "        all_histories.append({\n",
    "            'train_losses': train_losses,\n",
    "            'train_accs': train_accs,\n",
    "            'val_losses': val_losses,\n",
    "            'val_accs': val_accs\n",
    "        })\n",
    "        \n",
    "        print(f\"Fold {fold + 1} Best Val Accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return fold_results, all_histories\n",
    "\n",
    "def analyze_cv_results(fold_results, all_histories, label_map):\n",
    "    \"\"\"Analyze cross-validation results\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  CROSS-VALIDATION RESULTS SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Extract accuracies\n",
    "    best_accs = [result['best_val_acc'] for result in fold_results]\n",
    "    final_accs = [result['final_val_acc'] for result in fold_results]\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nBest Validation Accuracies per Fold:\")\n",
    "    for i, acc in enumerate(best_accs):\n",
    "        print(f\"  Fold {i+1}: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nCross-Validation Summary:\")\n",
    "    print(f\"  Mean Accuracy: {np.mean(best_accs):.4f} Â± {np.std(best_accs):.4f}\")\n",
    "    print(f\"  Best Fold: {np.max(best_accs):.4f}\")\n",
    "    print(f\"  Worst Fold: {np.min(best_accs):.4f}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Training loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for i, history in enumerate(all_histories):\n",
    "        plt.plot(history['train_losses'], label=f'Fold {i+1}', alpha=0.7)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Training accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for i, history in enumerate(all_histories):\n",
    "        plt.plot(history['train_accs'], label=f'Fold {i+1}', alpha=0.7)\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation accuracy\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for i, history in enumerate(all_histories):\n",
    "        plt.plot(history['val_accs'], label=f'Fold {i+1}', alpha=0.7)\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Overall confusion matrix (combine all folds)\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    for result in fold_results:\n",
    "        all_predictions.extend(result['val_predictions'])\n",
    "        all_true_labels.extend(result['val_true'])\n",
    "    \n",
    "    # Use your existing analyze_results function\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    \n",
    "    reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "    label_names = [reverse_label_map[i] for i in range(len(label_map))]\n",
    "    \n",
    "    cm = confusion_matrix(all_true_labels, all_predictions)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=label_names, yticklabels=label_names)\n",
    "    plt.title('Cross-Validation - Combined Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return np.mean(best_accs), np.std(best_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524fecb8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Check training set size and distribution\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Training label distribution:\")\n",
    "for label in set(train_labels):\n",
    "    count = train_labels.count(label)\n",
    "    print(f\"  {label}: {count}\")\n",
    "\n",
    "print(f\"\\nTest samples: {len(test_data)}\")\n",
    "print(f\"Test label distribution:\")\n",
    "for label in set(test_labels):\n",
    "    count = test_labels.count(label)\n",
    "    print(f\"  {label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3602ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_data + test_data\n",
    "all_labels = train_labels + test_labels\n",
    "\n",
    "print(f\"Starting cross-validation with {len(all_data)} total samples...\")\n",
    "print(f\"Label distribution: {dict(zip(*np.unique(all_labels, return_counts=True)))}\")\n",
    "\n",
    "# Run cross-validation experiment\n",
    "fold_results, all_histories = cross_validation_experiment(\n",
    "    all_data, all_labels, LABEL_MAP, \n",
    "    n_splits=4, epochs=50, batch_size=2  # Small batch size for small dataset\n",
    ")\n",
    "\n",
    "# Analyze results\n",
    "mean_acc, std_acc = analyze_cv_results(fold_results, all_histories, LABEL_MAP)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ FINAL RESULT: {mean_acc:.4f} Â± {std_acc:.4f} ({mean_acc*100:.1f}% Â± {std_acc*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fbfafb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
