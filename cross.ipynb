{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d50ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_subject_train.py\n",
    "import numpy as np\n",
    "import os\n",
    "from utilities import *\n",
    "import h5py\n",
    "from scipy.stats import zscore\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Use the same label mapping and model architecture as main.py\n",
    "LABEL_MAP = {\n",
    "    'rest': 0,\n",
    "    'task_motor': 1, \n",
    "    'task_story': 2,\n",
    "    'task_working': 3\n",
    "}\n",
    "\n",
    "class MEGDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for MEG data - same as main.py\"\"\"\n",
    "    def __init__(self, data_list, labels):\n",
    "        self.data_list = data_list\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_list[idx]\n",
    "        data = torch.FloatTensor(data).unsqueeze(0)\n",
    "        label = LABEL_MAP[self.labels[idx]]\n",
    "        label = torch.LongTensor([label]).squeeze()\n",
    "        return data, label\n",
    "\n",
    "class TinyMEGNet(nn.Module):\n",
    "    \"\"\"Same model architecture as main.py\"\"\"\n",
    "    def __init__(self, num_classes=4, input_channels=248, input_time_steps=2227):\n",
    "        super(TinyMEGNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=(32, 64), stride=(8, 16))\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=(4, 8), stride=(2, 4))\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(8, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        print(f\"TinyMEGNet created with {sum(p.numel() for p in self.parameters()):,} parameters\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def load_and_normalize_files_batch(directory_path, batch_size=8, downsample_factor=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Load and normalize h5 files in batches to manage memory for Cross dataset\n",
    "    \n",
    "    Parameters:\n",
    "    directory_path (str): Path to directory containing h5 files\n",
    "    batch_size (int): Number of files to load per batch\n",
    "    downsample_factor (int, optional): Factor by which to downsample the data\n",
    "    verbose (bool): Whether to print batch loading progress\n",
    "    \n",
    "    Yields:\n",
    "    tuple: (batch_data, batch_labels) for each batch\n",
    "    \"\"\"\n",
    "    h5_files = [f for f in os.listdir(directory_path) if f.endswith('.h5')]\n",
    "    if verbose:\n",
    "        print(f\"Found {len(h5_files)} files in {directory_path}\")\n",
    "    \n",
    "    # Process files in batches\n",
    "    for i in range(0, len(h5_files), batch_size):\n",
    "        batch_files = h5_files[i:i + batch_size]\n",
    "        batch_data = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Loading batch {i//batch_size + 1}/{(len(h5_files) + batch_size - 1)//batch_size} \"\n",
    "                  f\"(files {i+1}-{min(i+batch_size, len(h5_files))})\")\n",
    "        \n",
    "        for file in batch_files:\n",
    "            # Extract task type from filename\n",
    "            if file.startswith(\"task_\"):\n",
    "                parts = file.split('_')\n",
    "                task_type = '_'.join(parts[:2])\n",
    "            else:\n",
    "                task_type = file.split('_')[0]\n",
    "            \n",
    "            # Load and process the data\n",
    "            file_path = os.path.join(directory_path, file)\n",
    "            matrix = read_h5py_file(file_path)\n",
    "            \n",
    "            # Downsample if specified\n",
    "            if downsample_factor is not None:\n",
    "                matrix = matrix[:, ::downsample_factor]\n",
    "            \n",
    "            # Normalize using Z-score\n",
    "            normalized_matrix = zscore(matrix, axis=1, nan_policy='propagate')\n",
    "            normalized_matrix = np.nan_to_num(normalized_matrix, nan=0.0)\n",
    "            \n",
    "            batch_data.append(normalized_matrix)\n",
    "            batch_labels.append(task_type)\n",
    "        \n",
    "        yield batch_data, batch_labels\n",
    "\n",
    "def train_one_epoch_batched(model, train_path, criterion, optimizer, batch_size=8, \n",
    "                           downsample_factor=16, dataloader_batch_size=4, device='cpu', verbose=False):\n",
    "    \"\"\"\n",
    "    Train for one epoch using batched file loading\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    # Load and train on batches of files\n",
    "    for batch_data, batch_labels in load_and_normalize_files_batch(\n",
    "        train_path, batch_size=batch_size, downsample_factor=downsample_factor, verbose=verbose):\n",
    "        \n",
    "        # Create temporary dataset and dataloader for this batch\n",
    "        temp_dataset = MEGDataset(batch_data, batch_labels)\n",
    "        temp_dataloader = DataLoader(temp_dataset, batch_size=dataloader_batch_size, \n",
    "                                   shuffle=True, num_workers=0)\n",
    "        \n",
    "        # Train on this batch of files\n",
    "        for inputs, labels in temp_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        batch_count += 1\n",
    "        \n",
    "        # Clear memory\n",
    "        del temp_dataset, temp_dataloader, batch_data, batch_labels\n",
    "    \n",
    "    avg_loss = total_loss / (batch_count * dataloader_batch_size) if batch_count > 0 else 0\n",
    "    accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate_model_batched(model, test_path, criterion, batch_size=8, \n",
    "                          downsample_factor=16, dataloader_batch_size=4, device='cpu', verbose=False):\n",
    "    \"\"\"\n",
    "    Evaluate model using batched loading\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    batch_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in load_and_normalize_files_batch(\n",
    "            test_path, batch_size=batch_size, downsample_factor=downsample_factor, verbose=verbose):\n",
    "            \n",
    "            temp_dataset = MEGDataset(batch_data, batch_labels)\n",
    "            temp_dataloader = DataLoader(temp_dataset, batch_size=dataloader_batch_size, \n",
    "                                       shuffle=False, num_workers=0)\n",
    "            \n",
    "            for inputs, labels in temp_dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            batch_count += 1\n",
    "            del temp_dataset, temp_dataloader, batch_data, batch_labels\n",
    "    \n",
    "    avg_loss = total_loss / (batch_count * dataloader_batch_size) if batch_count > 0 else 0\n",
    "    accuracy = len([1 for i, j in zip(all_predictions, all_labels) if i == j]) / len(all_labels)\n",
    "    \n",
    "    return avg_loss, accuracy, all_predictions, all_labels\n",
    "\n",
    "def train_cross_subject_model(filepath, epochs=100, file_batch_size=8, dataloader_batch_size=4, \n",
    "                             downsample_factor=16, lr=0.001, weight_decay=1e-4):\n",
    "    \"\"\"\n",
    "    Train cross-subject model using the Cross dataset\n",
    "    \"\"\"\n",
    "    # Setup paths\n",
    "    cross_train_path = os.path.join(filepath, \"Cross\", \"train\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  CROSS-SUBJECT TRAINING\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Training data path: {cross_train_path}\")\n",
    "    print(f\"File batch size: {file_batch_size}\")\n",
    "    print(f\"DataLoader batch size: {dataloader_batch_size}\")\n",
    "    print(f\"Downsample factor: {downsample_factor}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "    \n",
    "    # Get sample data to determine input dimensions\n",
    "    sample_batch_data, sample_batch_labels = next(load_and_normalize_files_batch(\n",
    "        cross_train_path, batch_size=1, downsample_factor=downsample_factor, verbose=False))\n",
    "    \n",
    "    input_time_steps = sample_batch_data[0].shape[1]\n",
    "    print(f\"Input shape: (248, {input_time_steps})\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = TinyMEGNet(num_classes=len(LABEL_MAP), \n",
    "                      input_channels=248, \n",
    "                      input_time_steps=input_time_steps)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    \n",
    "    # Training history\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    \n",
    "    print(f\"\\nStarting training for {epochs} epochs...\")\n",
    "    \n",
    "    best_train_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    patience = 20\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Train for one epoch\n",
    "        train_loss, train_acc = train_one_epoch_batched(\n",
    "            model, cross_train_path, criterion, optimizer,\n",
    "            batch_size=file_batch_size, downsample_factor=downsample_factor,\n",
    "            dataloader_batch_size=dataloader_batch_size, verbose=(epoch % 20 == 0)\n",
    "        )\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # Early stopping based on training accuracy (since we don't have validation)\n",
    "        if train_acc > best_train_acc:\n",
    "            best_train_acc = train_acc\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), 'best_cross_subject_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch:3d}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses)\n",
    "    plt.title('Cross-Subject Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs)\n",
    "    plt.title('Cross-Subject Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n🎯 TRAINING COMPLETED\")\n",
    "    print(f\"Best training accuracy: {best_train_acc:.4f} ({best_train_acc*100:.1f}%)\")\n",
    "    print(f\"Model saved as 'best_cross_subject_model.pth'\")\n",
    "    \n",
    "def evaluate_cross_subject_model(filepath, model_path='best_cross_subject_model.pth', \n",
    "                               downsample_factor=16, file_batch_size=8, dataloader_batch_size=4):\n",
    "    \"\"\"\n",
    "    Evaluate the cross-subject model on all three test sets (test1, test2, test3)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  CROSS-SUBJECT MODEL EVALUATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load the trained model\n",
    "    print(f\"Loading model from {model_path}\")\n",
    "    model = TinyMEGNet(num_classes=len(LABEL_MAP), input_channels=248, input_time_steps=2227)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Test on all three test sets\n",
    "    test_sets = ['test1', 'test2', 'test3']\n",
    "    all_results = {}\n",
    "    \n",
    "    reverse_label_map = {v: k for k, v in LABEL_MAP.items()}\n",
    "    label_names = [reverse_label_map[i] for i in range(len(LABEL_MAP))]\n",
    "    \n",
    "    for test_set in test_sets:\n",
    "        test_path = os.path.join(filepath, \"Cross\", test_set)\n",
    "        print(f\"\\n--- Evaluating on {test_set} ---\")\n",
    "        \n",
    "        if not os.path.exists(test_path):\n",
    "            print(f\"Warning: {test_path} does not exist, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Get number of files\n",
    "        h5_files = [f for f in os.listdir(test_path) if f.endswith('.h5')]\n",
    "        print(f\"Found {len(h5_files)} files in {test_set}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        test_loss, test_acc, predictions, true_labels = evaluate_model_batched(\n",
    "            model, test_path, criterion, \n",
    "            batch_size=file_batch_size, downsample_factor=downsample_factor,\n",
    "            dataloader_batch_size=dataloader_batch_size, verbose=False\n",
    "        )\n",
    "        \n",
    "        all_results[test_set] = {\n",
    "            'loss': test_loss,\n",
    "            'accuracy': test_acc,\n",
    "            'predictions': predictions,\n",
    "            'true_labels': true_labels,\n",
    "            'num_samples': len(predictions)\n",
    "        }\n",
    "        \n",
    "        print(f\"{test_set} - Accuracy: {test_acc:.4f} ({test_acc*100:.1f}%), \"\n",
    "              f\"Loss: {test_loss:.4f}, Samples: {len(predictions)}\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(f\"\\n--- OVERALL RESULTS ---\")\n",
    "    all_accuracies = [results['accuracy'] for results in all_results.values()]\n",
    "    all_samples = [results['num_samples'] for results in all_results.values()]\n",
    "    \n",
    "    if all_accuracies:\n",
    "        weighted_avg_acc = sum(acc * samples for acc, samples in zip(all_accuracies, all_samples)) / sum(all_samples)\n",
    "        print(f\"Individual test accuracies: {[f'{acc:.3f}' for acc in all_accuracies]}\")\n",
    "        print(f\"Mean accuracy: {np.mean(all_accuracies):.4f} ± {np.std(all_accuracies):.4f}\")\n",
    "        print(f\"Weighted average accuracy: {weighted_avg_acc:.4f}\")\n",
    "        print(f\"Total test samples: {sum(all_samples)}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    if all_results:\n",
    "        plot_cross_subject_results(all_results, label_names)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def plot_cross_subject_results(all_results, label_names):\n",
    "    \"\"\"\n",
    "    Plot confusion matrices and accuracy comparison for cross-subject results\n",
    "    \"\"\"\n",
    "    n_tests = len(all_results)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, max(2, n_tests), figsize=(5*n_tests, 10))\n",
    "    if n_tests == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    # Plot confusion matrices for each test set\n",
    "    for i, (test_name, results) in enumerate(all_results.items()):\n",
    "        if i < n_tests:  # Only plot if we have space\n",
    "            ax = axes[0, i] if n_tests > 1 else axes[0]\n",
    "            \n",
    "            cm = confusion_matrix(results['true_labels'], results['predictions'])\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                       xticklabels=label_names, yticklabels=label_names, ax=ax)\n",
    "            ax.set_title(f'{test_name}\\nAccuracy: {results[\"accuracy\"]:.3f}')\n",
    "            ax.set_ylabel('True Label')\n",
    "            ax.set_xlabel('Predicted Label')\n",
    "    \n",
    "    # Hide extra subplots in first row\n",
    "    for i in range(n_tests, axes.shape[1]):\n",
    "        axes[0, i].set_visible(False)\n",
    "    \n",
    "    # Plot accuracy comparison\n",
    "    ax_acc = axes[1, 0] if n_tests > 1 else axes[1]\n",
    "    test_names = list(all_results.keys())\n",
    "    accuracies = [all_results[test]['accuracy'] for test in test_names]\n",
    "    \n",
    "    bars = ax_acc.bar(test_names, accuracies, color=['skyblue', 'lightcoral', 'lightgreen'][:len(test_names)])\n",
    "    ax_acc.set_title('Cross-Subject Test Accuracies')\n",
    "    ax_acc.set_ylabel('Accuracy')\n",
    "    ax_acc.set_ylim(0, 1)\n",
    "    \n",
    "    # Add accuracy labels on bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        ax_acc.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                   f'{acc:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Add horizontal line at 0.25 (random chance for 4 classes)\n",
    "    ax_acc.axhline(y=0.25, color='red', linestyle='--', alpha=0.7, label='Random chance (25%)')\n",
    "    ax_acc.legend()\n",
    "    \n",
    "    # Hide extra subplots in second row\n",
    "    for i in range(1, axes.shape[1]):\n",
    "        axes[1, i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed classification reports\n",
    "    print(f\"\\n--- DETAILED CLASSIFICATION REPORTS ---\")\n",
    "    for test_name, results in all_results.items():\n",
    "        print(f\"\\n{test_name.upper()}:\")\n",
    "        print(classification_report(results['true_labels'], results['predictions'], \n",
    "                                  target_names=label_names, digits=3))\n",
    "\n",
    "def analyze_overfitting(train_losses, train_accs, all_results):\n",
    "    \"\"\"\n",
    "    Analyze potential overfitting by comparing training vs test performance\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  OVERFITTING ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    final_train_acc = train_accs[-1] if train_accs else 0\n",
    "    test_accuracies = [results['accuracy'] for results in all_results.values()]\n",
    "    \n",
    "    if test_accuracies:\n",
    "        avg_test_acc = np.mean(test_accuracies)\n",
    "        performance_gap = final_train_acc - avg_test_acc\n",
    "        \n",
    "        print(f\"Final training accuracy: {final_train_acc:.4f} ({final_train_acc*100:.1f}%)\")\n",
    "        print(f\"Average test accuracy: {avg_test_acc:.4f} ({avg_test_acc*100:.1f}%)\")\n",
    "        print(f\"Performance gap: {performance_gap:.4f} ({performance_gap*100:.1f} percentage points)\")\n",
    "        \n",
    "        if performance_gap > 0.3:  # 30% gap\n",
    "            print(\"\\n🚨 SEVERE OVERFITTING DETECTED!\")\n",
    "            print(\"Recommendations:\")\n",
    "            print(\"  - Reduce model complexity\")\n",
    "            print(\"  - Add more regularization (dropout, weight decay)\")\n",
    "            print(\"  - Use data augmentation\")\n",
    "            print(\"  - Reduce training epochs / use early stopping\")\n",
    "            print(\"  - Increase dataset size if possible\")\n",
    "        elif performance_gap > 0.15:  # 15% gap\n",
    "            print(\"\\n⚠️  MODERATE OVERFITTING DETECTED\")\n",
    "            print(\"Recommendations:\")\n",
    "            print(\"  - Increase regularization\")\n",
    "            print(\"  - Monitor validation loss during training\")\n",
    "        else:\n",
    "            print(\"\\n✅ REASONABLE GENERALIZATION\")\n",
    "    \n",
    "    # Plot training curve vs test performance\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_accs, label='Training Accuracy', color='blue')\n",
    "    if test_accuracies:\n",
    "        plt.axhline(y=np.mean(test_accuracies), color='red', linestyle='--', \n",
    "                   label=f'Avg Test Acc ({np.mean(test_accuracies):.3f})')\n",
    "    plt.title('Training vs Test Performance')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_losses, label='Training Loss', color='orange')\n",
    "    plt.title('Training Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Add evaluation to the main function\n",
    "def run_complete_cross_subject_experiment(filepath, **kwargs):\n",
    "    \"\"\"\n",
    "    Run complete cross-subject experiment: train + evaluate + analyze\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model, train_losses, train_accs = train_cross_subject_model(filepath, **kwargs)\n",
    "    \n",
    "    # Evaluate on test sets\n",
    "    test_results = evaluate_cross_subject_model(filepath)\n",
    "    \n",
    "    # Analyze overfitting\n",
    "    analyze_overfitting(train_losses, train_accs, test_results)\n",
    "    \n",
    "    return model, train_losses, train_accs, test_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7844298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base filepath: /Users/jesseh/Library/Mobile Documents/com~apple~CloudDocs/AA Master AI/Deep Learning\n",
      "\n",
      "============================================================\n",
      "  CROSS-SUBJECT TRAINING\n",
      "============================================================\n",
      "Training data path: /Users/jesseh/Library/Mobile Documents/com~apple~CloudDocs/AA Master AI/Deep Learning/Cross/train\n",
      "File batch size: 8\n",
      "DataLoader batch size: 2\n",
      "Downsample factor: 16\n",
      "Learning rate: 0.001\n",
      "Weight decay: 0.01\n",
      "Input shape: (248, 2227)\n",
      "TinyMEGNet created with 9,264 parameters\n",
      "\n",
      "Starting training for 25 epochs...\n",
      "Found 64 files in /Users/jesseh/Library/Mobile Documents/com~apple~CloudDocs/AA Master AI/Deep Learning/Cross/train\n",
      "Loading batch 1/8 (files 1-8)\n",
      "Loading batch 2/8 (files 9-16)\n",
      "Loading batch 3/8 (files 17-24)\n",
      "Loading batch 4/8 (files 25-32)\n",
      "Loading batch 5/8 (files 33-40)\n",
      "Loading batch 6/8 (files 41-48)\n",
      "Loading batch 7/8 (files 49-56)\n",
      "Loading batch 8/8 (files 57-64)\n",
      "Epoch   0: Train Loss=2.8131, Train Acc=0.2500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get filepath using existing utilities\n",
    "filepath = get_filepath()\n",
    "print(f\"Base filepath: {filepath}\")\n",
    "\n",
    "# Option 1: Run complete experiment (train + evaluate + analyze)\n",
    "model, losses, accs, test_results = run_complete_cross_subject_experiment(\n",
    "    filepath=filepath,\n",
    "    epochs=25,                # Reduced from 100 to prevent overfitting\n",
    "    file_batch_size=8,        \n",
    "    dataloader_batch_size=2,  \n",
    "    downsample_factor=16,     \n",
    "    lr=0.001,                 # Reduced learning rate\n",
    "    weight_decay=1e-2         # Increased weight decay for more regularization\n",
    ")\n",
    "\n",
    "# Option 2: Just evaluate existing model (uncomment if you have a trained model)\n",
    "# test_results = evaluate_cross_subject_model(filepath)\n",
    "\n",
    "print(\"\\n🎯 Cross-subject experiment completed!\")\n",
    "print(\"Check the plots and analysis above to understand overfitting.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
