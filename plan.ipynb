{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b410b82d",
   "metadata": {},
   "source": [
    "## ✅ OVERALL STRATEGY\n",
    "\n",
    "> **Start simple → Validate → Add complexity**\n",
    "> Don't jump into the full CNN+LSTM model immediately. It's better to:\n",
    "\n",
    "1. Build a **baseline (e.g., simple CNN)**.\n",
    "2. **Verify your pipeline** (data loading, training loop, evaluation).\n",
    "3. Then incrementally add **LSTM**, **regularization**, and **improvements**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧭 STEP-BY-STEP GUIDE\n",
    "\n",
    "### 🧩 1. **Data Handling and Preprocessing**\n",
    "\n",
    "* ✅ **Load `.h5` files** using `h5py`, extract the matrix.\n",
    "* ✅ **Normalize** the data: use **Z-score** or **min-max scaling** along time axis.\n",
    "* ✅ **Downsample** the time axis (e.g., from 35624 → 1000 or 2000 steps).\n",
    "* ✅ **Label parsing**: extract task labels (`rest`, `math`, etc.) from file names.\n",
    "\n",
    "👉 **Goal**: Have a `(X, y)` dataset ready per file.\n",
    "\n",
    "---\n",
    "\n",
    "### 🛠 2. **Custom PyTorch Dataset + Dataloader**\n",
    "\n",
    "* Write a `torch.utils.data.Dataset` class:\n",
    "\n",
    "  * Inputs: paths to `.h5` files\n",
    "  * Outputs: `tensor(shape=[248, downsampled_time]), label`\n",
    "* Use `DataLoader` with batching, shuffling, etc.\n",
    "\n",
    "👉 **Goal**: Robust, memory-efficient data loading pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 3. **Build a Simple Baseline Model (CNN only)**\n",
    "\n",
    "* Use a **basic CNN**:\n",
    "\n",
    "  * `Conv1D` or `Conv2D` across the MEG input\n",
    "  * Pooling, Flatten, Dense → Softmax\n",
    "* Train on **Intra-subject** data\n",
    "\n",
    "👉 **Goal**: Ensure your pipeline, training loop, and loss/accuracy tracking all work.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 4. **Upgrade to CNN + LSTM Hybrid**\n",
    "\n",
    "* Add an LSTM layer **after CNN feature extraction**:\n",
    "\n",
    "  * CNN output → reshape to `[batch, time, features]`\n",
    "  * Feed into LSTM → output → Dense → Softmax\n",
    "\n",
    "👉 **Goal**: Capture spatial + temporal patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 5. **Evaluate Intra-Subject Performance**\n",
    "\n",
    "* Train on `Intra/train`, test on `Intra/test`\n",
    "* Track accuracy, loss, confusion matrix\n",
    "\n",
    "👉 **Goal**: Verify model can learn one person’s patterns\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 6. **Train & Evaluate Cross-Subject Model**\n",
    "\n",
    "* Train on `Cross/train` (2 subjects)\n",
    "* Test on `Cross/test1`, `test2`, `test3` (3 new subjects)\n",
    "\n",
    "👉 **Goal**: Evaluate generalization capability\n",
    "\n",
    "---\n",
    "\n",
    "### 🎛 7. **Tune Hyperparameters**\n",
    "\n",
    "* Adjust:\n",
    "\n",
    "  * Learning rate\n",
    "  * Batch size\n",
    "  * Downsampling rate\n",
    "  * LSTM hidden size\n",
    "  * Dropout, number of filters\n",
    "* Use early stopping and validation splits\n",
    "\n",
    "👉 **Goal**: Improve generalization without overfitting\n",
    "\n",
    "---\n",
    "\n",
    "### 📉 8. **Analyze Results**\n",
    "\n",
    "* Compare:\n",
    "\n",
    "  * Intra vs. Cross accuracy\n",
    "  * Confusion matrices per class\n",
    "* Identify:\n",
    "\n",
    "  * Overfitting?\n",
    "  * Class imbalance?\n",
    "  * Which tasks are hard to classify?\n",
    "\n",
    "👉 **Goal**: Understand model behavior\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 9. **Optional: Add Improvements**\n",
    "\n",
    "If performance gaps are found:\n",
    "\n",
    "* Add **batch normalization**, **dropout**, or **data augmentation**\n",
    "* Try **EEGNet-style blocks** or **domain adaptation** later\n",
    "\n",
    "👉 **Goal**: Explore performance ceiling\n",
    "\n",
    "---\n",
    "\n",
    "## ⏳ Timeline Suggestion (if you’re pacing this)\n",
    "\n",
    "| Week | Focus                                |\n",
    "| ---- | ------------------------------------ |\n",
    "| 1    | Data loading + preprocessing         |\n",
    "| 2    | Dataset class + simple CNN baseline  |\n",
    "| 3    | Add LSTM → CNN+LSTM hybrid           |\n",
    "| 4    | Intra-subject training/testing       |\n",
    "| 5    | Cross-subject training/testing       |\n",
    "| 6    | Hyperparameter tuning + analysis     |\n",
    "| 7    | Final tweaks or add advanced methods |\n",
    "| 8    | Write-up and visualization           |\n",
    "\n",
    "---\n",
    "\n",
    "## Final Tip:\n",
    "\n",
    "**Start small, scale carefully.** A working simple CNN pipeline is 100× more valuable than a broken CNN+LSTM+Transformer+GAN hybrid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e8548",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
